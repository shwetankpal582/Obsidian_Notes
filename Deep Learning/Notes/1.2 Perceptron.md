 ****Perceptron**** is a type of [neural network](https://www.geeksforgeeks.org/neural-networks-a-beginners-guide/) that performs binary classification that maps input features to an output decision, usually classifying data into one of two categories, such as 0 or 1.

Perceptron consists of a single layer of input nodes that are fully connected to a layer of output nodes. It is particularly good at learning ****linearly separable patterns****. It utilizes a variation of artificial neurons called ****Threshold Logic Units (TLU)****, which were first introduced by McCulloch and Walter Pitts in the 1940s. This foundational model has played a crucial role in the development of more advanced neural networks and machine learning algorithms.

### Types of Perceptron

1. [****Single-Layer Perceptron****](https://www.geeksforgeeks.org/single-layer-perceptron-in-tensorflow/) is a type of perceptron is limited to learning linearly separable patterns. It is effective for tasks where the data can be divided into distinct categories through a straight line. While powerful in its simplicity, it struggles with more complex problems where the relationship between inputs and outputs is non-linear.
2. [****Multi-Layer Perceptron****](https://www.geeksforgeeks.org/multi-layer-perceptron-learning-in-tensorflow/) possess enhanced processing capabilities as they consist of two or more layers, adept at handling more complex patterns and relationships within the data.

## Basic Components of Perceptron

A Perceptron is composed of key components that work together to process information and make predictions.

- ****Input Features:**** The perceptron takes multiple input features, each representing a characteristic of the input data.
- [****Weights****](https://www.geeksforgeeks.org/the-role-of-weights-and-bias-in-neural-networks/)****:**** Each input feature is assigned a weight that determines its influence on the output. These weights are adjusted during training to find the optimal values.
- ****Summation Function:**** The perceptron calculates the weighted sum of its inputs, combining them with their respective weights.
- [****Activation Function****](https://www.geeksforgeeks.org/activation-functions-neural-networks/)****:**** The weighted sum is passed through the ****Heaviside step function****, comparing it to a threshold to produce a binary output (0 or 1).
- ****Output:**** The final output is determined by the activation function, often used for ****binary classification**** tasks.
- [****Bias****](https://www.geeksforgeeks.org/effect-of-bias-in-neural-network/)****:**** The bias term helps the perceptron make adjustments independent of the input, improving its flexibility in learning.
- ****Learning Algorithm:**** The perceptron adjusts its weights and bias using a learning algorithm, such as the Perceptron Learning Rule, to minimize prediction errors.

These components enable the perceptron to learn from data and make predictions. While a single perceptron can handle simple binary classification, complex tasks require multiple perceptrons organized into layers, forming a neural network.