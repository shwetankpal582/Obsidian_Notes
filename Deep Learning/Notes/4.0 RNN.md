---
tags:
  - RNN
  - DL
Date: 2025 - 03 - 06
Topic:
  - RNN
Subject: DL
unit: 4
---
## Recurrent Neural Network

In neural network the information flows in one direction from input to output. However in RNN information is fed back into the system after each step. 

RNNs allow the network to "remember" past information by feeding the output from one step into next step. This helps the network understand the context of what has already happened and make better predictions based on that. 

For example 
	when predicting the next word in a sentence the RNN uses the previous words to help decide what word is most likely to come next.
	Think of it like reading a sentence, when you're trying to predict the next word you don’t just look at the current word but also need to remember the words that came before to make accurate guess.

## How RNN Differs from Feedforward Neural Networks?

Feedforward Neural Networks (FNNs) 
	process data in one direction from input to output without retaining information from previous inputs. This makes them suitable for tasks with independent inputs like image classification. However FNNs struggle with sequential data since they lack memory.

Recurrent Neural Networks (RNNs) 
	solve this by incorporating loops that allow information from previous steps to be fed back into the network. This feedback enables RNNs to remember prior inputs making them ideal for tasks where context is important
