In **Stochastic Gradient Descent**, **one training sample** is used to update the model’s parameters at a time.

### 🔄 Update Rule:

θ=θ−α⋅∇θL(θ;x(i),y(i))\theta = \theta - \alpha \cdot \nabla_\theta L(\theta; x^{(i)}, y^{(i)})θ=θ−α⋅∇θ​L(θ;x(i),y(i))

Where:

- θ\thetaθ = model parameters (weights)
    
- α\alphaα = learning rate
    
- LLL = loss function
    
- (x(i),y(i))(x^{(i)}, y^{(i)})(x(i),y(i)) = a single training example
    

---

## 🔹 Difference from Batch Gradient Descent

|Method|Data Used per Update|Speed|Stability|
|---|---|---|---|
|Batch Gradient Descent|All training data|Slow|Stable|
|**SGD**|1 training sample|Fast|Noisy|
|Mini-Batch Gradient Descent|Small batch (e.g., 32 samples)|Balanced|Balanced|

---

## 🔹 Pros and Cons of SGD

### ✅ Advantages:

- Fast updates = quick progress
    
- Good for large datasets
    
- Can escape local minima due to noise in updates
    

### ❌ Disadvantages:

- Updates are noisy (fluctuate a lot)
    
- May not converge smoothly
    
- Sensitive to learning rate
    

---

## 🔹 Improvements to SGD

To reduce instability, several variants exist:

- **SGD with Momentum**: smooths updates using previous gradients
    
- **Nesterov Accelerated Gradient (NAG)**
    
- **SGD with learning rate decay**
    
- **Adam**, **RMSProp** (adaptive optimizers that extend SGD)