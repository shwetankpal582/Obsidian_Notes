In **Stochastic Gradient Descent**, **one training sample** is used to update the modelâ€™s parameters at a time.

### ğŸ”„ Update Rule:

Î¸=Î¸âˆ’Î±â‹…âˆ‡Î¸L(Î¸;x(i),y(i))\theta = \theta - \alpha \cdot \nabla_\theta L(\theta; x^{(i)}, y^{(i)})Î¸=Î¸âˆ’Î±â‹…âˆ‡Î¸â€‹L(Î¸;x(i),y(i))

Where:

- Î¸\thetaÎ¸ = model parameters (weights)
    
- Î±\alphaÎ± = learning rate
    
- LLL = loss function
    
- (x(i),y(i))(x^{(i)}, y^{(i)})(x(i),y(i)) = a single training example
    

---

## ğŸ”¹ Difference from Batch Gradient Descent

|Method|Data Used per Update|Speed|Stability|
|---|---|---|---|
|Batch Gradient Descent|All training data|Slow|Stable|
|**SGD**|1 training sample|Fast|Noisy|
|Mini-Batch Gradient Descent|Small batch (e.g., 32 samples)|Balanced|Balanced|

---

## ğŸ”¹ Pros and Cons of SGD

### âœ… Advantages:

- Fast updates = quick progress
    
- Good for large datasets
    
- Can escape local minima due to noise in updates
    

### âŒ Disadvantages:

- Updates are noisy (fluctuate a lot)
    
- May not converge smoothly
    
- Sensitive to learning rate
    

---

## ğŸ”¹ Improvements to SGD

To reduce instability, several variants exist:

- **SGD with Momentum**: smooths updates using previous gradients
    
- **Nesterov Accelerated Gradient (NAG)**
    
- **SGD with learning rate decay**
    
- **Adam**, **RMSProp** (adaptive optimizers that extend SGD)