An autoencoder is a type of neural network architecture used in Deep Learning for unsupervised learning and dimensionality reduction tasks. It is primarily designed to learn efficient representations of data by encoding it into a lower-dimensional laten space and then decoding it back to the original data space. Autoencoders are widely used to various applications, including data compression, denoising, feature learning, and anamaly detection.

**Encoders :**
	Used for data Compression
	After compression data is converted into lower dimension
	Compressed data is called Encoded Data

**Decoders : **
	Used for reconstruct compressed data

**Visual Representation**

![[Pasted image 20250517040328.png]]

### Architecture

Autoencoders consist of main two parts :
	- An Encoder
	- A Decoder

**Encoder :** 

The encoder network takes the input data and maps it to a lower-dimensional representation, often called the encoding or latent space. This encoding is typically a compressed representation of the input data. The encoder can consist of one or more hidden layers and user activation functions like ReLu (Rectified Linear Unit).

**Decoder :**
![[Pasted image 20250517045632.png]]

The decoder network takes the encoded representation and attempts to reconstruct the original input data from it. Like the encoder, the decoder can also have one or more hidden layers and used activation function.

**Objective :**

The main objective of an autoencoder is to minimize the reconstruction error, which measures how well the decoder can reconstruct the input data from the encoding. Common loss functions used for this purpose include mean sq