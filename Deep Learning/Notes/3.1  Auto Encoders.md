An autoencoder is a type of neural network architecture used in Deep Learning for unsupervised learning and dimensionality reduction tasks. It is primarily designed to learn efficient representations of data by encoding it into a lower-dimensional laten space and then decoding it back to the original data space. Autoencoders are widely used to various applications, including data compression, denoising, feature learning, and anamaly detection.

**Encoders :**
	Used for data Compression
	After compression data is converted into lower dimension
	Compressed data is called Encoded Data

**Decoders :** 
	Used for reconstruct compressed data

**Visual Representation**

![[Pasted image 20250517040328.png]]

### 1. Architecture

Autoencoders consist of main two parts :
	- An Encoder
	- A Decoder

**1.1 Encoder :** 
The encoder network takes the input data and maps it to a lower-dimensional representation, often called the encoding or latent space. This encoding is typically a compressed representation of the input data. The encoder can consist of one or more hidden layers and user activation functions like ReLu (Rectified Linear Unit).

**1.2 Decoder :**
The decoder network takes the encoded representation and attempts to reconstruct the original input data from it. Like the encoder, the decoder can also have one or more hidden layers and used activation function.

**2 Objective :**
The main objective of an autoencoder is to minimize the reconstruction error, which measures how well the decoder can reconstruct the input data from the encoding. Common loss functions used for this purpose include mean squared error (MSE) or binary cross entropy, depending on the type of data (continuous or binary) and the specific task.

**3 Training :**
Autoencoders are trained in an unsupervised manner, which means they don't require labeled data. The training process involves feeding input data into the encoder, encoding it into a lower dimensional representation, and then decoding it back to the original data. The difference between the input and the reconstructed output is used to compute the loss, which is minimized during training using optimization techniques like gradient decent.

**4 Variations of Autoencoders :**
- Denoising Autoencoder
- Sparse Autoencoder
- Variational Autoencoder
- Convolutional Autoencoder
- Recurrent Autoencoder

**Denoising  Autoencoder :**
	Trained to remove noise from data by corrupting the input and reconstructing the clean data.

**Sparse Autoencoder :**
	Encourages the network to learn sparse representation which can be useful to feature learning and dimensionality reduction.

**Variational Autoencoder :**
	Introduces probabilistic elements in the latent space, allowing for generation of new data samples and improved data compression.

**Convolutional Autoencoder :**
	Specifically designed for image data, using convolutional layers in the encoder and decoder.

**Recurrent Autoencoder :**
	Suitable for sequential data, such as time series, by using recurrent layers in the architecture.
	
**Working**
- Input Data
- Encoder
- Decoder
- Loss Function
![[Pasted image 20250517051728.png]]

