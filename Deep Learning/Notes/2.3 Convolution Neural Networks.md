---
tags:
  - Convolution_Neural_Networks
  - DL
Date: 2025 - 03 - 06
Topic:
  - Convolution Neural Networks
  - DL
Subject: DL
unit: 2
---
CNN (Convolution Neural Networks)
	They are specially designed to work with images. In DL images are represented as arrays of pixel values.

**There are 4 Layers of CNN**

- Convolutional Layer
- ReLU
- Pooling Layers
- Fully connected (dense) Layers


**Operation on CNN**

- Convolution Operation
- Pooling Operation
- Flatten Operation
- Classification Operation

## Convolutional Layer and convolution operation

This is first layer in CNN. It takes images as input and begins to process
	**There are 3 main elements in convolutional layer**
		Input Image
		Filters / Kernal
		Feature Map / Convoluted Map


![[Pasted image 20250403204043.png]]

Stride : The number of steps (pixels) that we shift the filter over the input image

Filter : Used to multiply with input image to get convoluted feature and also called kernal / Filter detector

Image Section :  The size of the image section should be equal to the size of the
filter(s) we choose. The number of image sections depends on the Stride.

Feature map: The feature map stores the outputs of different convolution
operations between different image sections and the filter(s).


## ReLU (Rectified Linear Unit)

- Function: The ReLU layer introduces non-linearity to the network by applying the Rectified Linear Unit activation function.

- Operations: ReLU activation sets all negative values in the feature map to zero and leaves positive values unchanged: f(x) =max (O,x) .

- Advantages: ReLU helps in overcoming the vanishing gradient problem and accelerates convergence during training.


## Pooling Layers

The Pooling layer is responsible for reducing the spatial size of the Convolved
Feature. This is to decrease the computational power required to process the data
by reducing the dimensions.

**There are two types of pooling operations.**

 - Max pooling: Get the maximum value in the area where the filter is applied.
 - Average pooling: Get the average of the values in the area where the filter is applied.


## Flattening

 - The next step in the process is called flattening. Flattening is used to convert all the resultant 2-Dimensional arrays from pooled feature maps into a single long continuous linear vector.
 - The flattened matrix is fed as input to the fully connected layer to classify the image.


## Fully connected (dense) Layers


-  Function: The fully connected layer is a traditional-neural network layer where neuron is connected to every neuron in the previous and subsequent layers.
-  Operations: The output of the previous layers is flattened into a vector and connected to the neurons of the fully connected layer. This layer learns complex patterns and relationships in the data.
 -  Parameters: The number of neurons in the fully connected layer is a crucial parameter that affects the model's capacity.

![[Pasted image 20250413132221.png]]


# ###  Summary

ðŸ”¹ **Convolution Layers**

These layers apply filters (kernels) to the input image to **extract features** such as edges, corners, textures, or shapes. The result is a **feature map** that highlights important areas of the image.

---

### ðŸ”¹ **Pooling Layer**

Pooling reduces the size of the feature maps by summarizing regions (usually with **max** or **average** pooling). This helps in:

- Reducing computation
    
- Preventing overfitting
    
- Making features more **invariant to translation**
    

---

### ðŸ”¹ **Flattening**

After convolution and pooling, the multi-dimensional data (feature maps) is **flattened** into a 1D vector. This prepares the data to be input into the fully connected (dense) layers.

---

### ðŸ”¹ **Fully Connected Layers**

These layers perform the **final classification or regression**. Every neuron is connected to all neurons in the previous layer. They combine all extracted features and make the final decision (e.g., output a class label).