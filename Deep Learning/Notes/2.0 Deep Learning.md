Deep Learning is transforming the way machines understand, learn, and interact with complex data. Deep learning mimics neural networks of the human brain, it enables computers to autonomously uncover patterns and make informed decisions from vast amounts of unstructured data.

Deep Learning consist of 3 main layers : 
	Input layer (Receives data)
	Hidden layer (Process data)
	Output layer (Generate model's prediction)
## Deep Learning in Machine Learning Paradigms

- **Supervised Learning** 
	-  Neural networks learn from labeled data to predict or classify, using algorithms like CNNs and RNNs for tasks such as image recognition and language translation.

- **Unsupervised Learning**
	- Neural networks identify patterns in unlabeled data, using techniques like Autoencoders and Generative Models for tasks like clustering and anomaly detection.

- **Reinforcement Learning**
	- An agent learns to make decisions by maximizing rewards, with algorithms like DQN and DDPG applied in areas like robotics and game playing.

## Difference between Machine Learning and Deep Learning

| Machine Learning                                                                                                   | Deep Learning                                                                                              |
| ------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------- |
| Apply statistical algorithms to learn the hidden patterns and relationships in the dataset.                        | Uses artificial neural network architecture to learn the hidden patterns and relationships in the dataset. |
| Can work on the smaller amount of dataset                                                                          | Requires the larger volume of dataset compared to machine learning                                         |
| Better for the low-label task.                                                                                     | Better for complex task like image processing, natural language processing, etc.                           |
| Takes less time to train the model.                                                                                | Takes more time to train the model.                                                                        |
| A model is created by relevant features which are manually extracted from images to detect an object in the image. | Relevant features are automatically extracted from images. It is an end-to-end learning process.           |
| Less complex and easy to interpret the result.                                                                     | More complex, it works like the black box interpretations of the result are not easy.                      |
| It can work on the CPU or requires less computing power as compared to deep learning.                              | It requires a high-performance computer with GPU.                                                          |
## Types of neural networks

**Feedforward neural networks (FNNs)**
	are the simplest type of ANN, where data flows in one direction from input to output. It is used for basic tasks like classification.

Convolutional Neural Networks (CNNs)
	are specialized for processing grid-like data, such as images. CNNs use convolutional layers to detect spatial hierarchies, making them ideal for computer vision tasks.

Recurrent Neural Networks (RNNs)
	are able to process sequential data, such as time series and natural language. RNNs have loops to retain information over time, enabling applications like language modeling and speech recognition. Variants like LSTMs and GRUs address vanishing gradient issues.

Generative Adversarial Networks (GANs)
	consist of two networks—a generator and a discriminator—that compete to create realistic data. GANs are widely used for image generation, style transfer, and data augmentation.

Autoencoders
	 are unsupervised networks that learn efficient data encodings. They compress input data into a latent representation and reconstruct it, useful for dimensionality reduction and anomaly detection.

Transformer Networks
	has revolutionized NLP with self-attention mechanisms. Transformers excel at tasks like translation, text generation, and sentiment analysis, powering models like GPT and BERT.