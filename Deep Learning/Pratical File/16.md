WAP TO IMPLEMENT BASIC REINFORCEMENT LEARNING ALGORITHM TO TEACH A BOT TO REACH ITSÂ DESTINATION.

## Code

```
import numpy as np  
import random  

# Environment setup  
size = 5  # Grid size 5x5  
goal_state = (4, 4)  
obstacles = [(1, 1), (2, 2), (3, 1)]  # Obstacles positions  

# Initialize Q-table: State-action pairs  
Q = np.zeros((size, size, 4))  # 4 actions: up, down, left, right  

# Parameters  
epsilon = 0.9  # Exploration rate  
alpha = 0.1    # Learning rate  
gamma = 0.9  # Discount factor  
episodes = 1000  

# Helper functions  
def is_valid(x, y):  
    if x < 0 or x >= size or y < 0 or y >= size:  
        return False  
    if (x, y) in obstacles:  
        return False  
    return True  

def get_next_state(x, y, action):  
    # Actions: 0=up, 1=down, 2=left, 3=right  
    if action == 0:  
        nx, ny = x - 1, y  
    elif action == 1:  
        nx, ny = x + 1, y  
    elif action == 2:  
        nx, ny = x, y - 1  
    else:  
        nx, ny = x, y + 1  
    if is_valid(nx, ny):  
        return nx, ny  
    return x, y  # if invalid, stay in same cell  

# Training  
for episode in range(episodes):  
    x, y = 0, 0  # start position  
    step = 0  
    while (x, y) != goal_state and step < 100:  
        if random.random() < epsilon:  
            action = np.argmax(Q[x, y])  # Exploit  
        else:  
            action = np.random.randint(4)  # Explore  

        nx, ny = get_next_state(x, y, action)  
        reward = 1 if (nx, ny) == goal_state else -0.1  

        # Update Q-value  
        Q[x, y, action] += alpha * (reward + gamma * np.max(Q[nx, ny]) - Q[x, y, action])  

        x, y = nx, ny  
        step += 1  

# Testing the learned policy  
x, y = 0, 0  
path = [(x, y)]  
while (x, y) != goal_state:  
    action = np.argmax(Q[x, y])  
    x, y = get_next_state(x, y, action)  
    path.append((x, y))  
    if len(path) > 50:  
        break  

# Output the path  
print("Path to reach destination: ")  
for step in path:  
    print(step)
```

## Output

```
Path to reach destination:  
(0, 0)  
(1, 0)  
(2, 0)  
(3, 0)  
(4, 0)  
(4, 1)  
(4, 2)  
(4, 3)  
(4, 4)
```