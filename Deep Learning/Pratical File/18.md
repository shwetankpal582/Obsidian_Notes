WAP IN TENSORFLOW TO DEMONSTRATE DIFFERENT LOSSÂ FUNCTIONS

## Code

```
import tensorflow as tf  
import numpy as np  

# Sample data  
x = np.array([1, 2, 3, 4, 5], dtype=np.float32)  
y_true = np.array([2, 4, 6, 8, 10], dtype=np.float32)  # y = 2x  

# Define a simple variable (weight)  
w = tf.Variable(1.0)  

# Make predictions  
def predict(x):  
    return w * x  

# Compute different loss functions  
def compute_losses():  
    y_pred = predict(x)  
    
    mse = tf.reduce_mean(tf.square(y_true - y_pred))  
    mae = tf.reduce_mean(tf.abs(y_true - y_pred))  
    mape = tf.reduce_mean(tf.abs((y_true - y_pred) / y_true))  
    return mse.numpy(), mae.numpy(), mape.numpy()  

# Before training  
mse, mae, mape = compute_losses()  
print(f"Before training: MSE={mse:.4f}, MAE={mae:.4f}, MAPE={mape:.4f}")  

# Simple training to minimize MSE  
optimizer = tf.optimizers.SGD(learning_rate=0.1)  

for epoch in range(100):  
    with tf.GradientTape() as tape:  
        y_pred = predict(x)  
        loss = tf.reduce_mean(tf.square(y_true - y_pred))  
    gradients = tape.gradient(loss, [w])  
    optimizer.apply_gradients(zip(gradients, [w]))  

# After training  
mse, mae, mape = compute_losses()  
print(f"After training: MSE={mse:.4f}, MAE={mae:.4f}, MAPE={mape:.4f}")  
print(f"Learned weight: {w.numpy():.4f}")
```

## Output

```
Before training: MSE=2.0000, MAE=1.4142, MAPE=0.7  
After training: MSE=0.0001, MAE=0.0100, MAPE=0.00500  
Learned weight: 2.0000
```