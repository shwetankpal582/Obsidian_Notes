WAP TO DEMONSTRATE AUTO ENCODER

-  DENOISING AUTO ENCODER
-  SPARSE AUTO ENCODER
-  VARIATIONAL AUTO ENCODER

## Code

### 1. Basic Autoencoder

```
import numpy as np  
import matplotlib.pyplot as plt  
from tensorflow.keras.layers import Input, Dense  
from tensorflow.keras.models import Model  
from tensorflow.keras.datasets import mnist  

# Load data  
(x_train, _), (x_test, _) = mnist.load_data()  

# Normalize and flatten  
x_train = x_train.astype('float32') / 255.  
x_test = x_test.astype('float32') / 255.  
x_train = x_train.reshape((len(x_train), -1))  
x_test = x_test.reshape((len(x_test), -1))  

# Autoencoder architecture  
input_dim = x_train.shape[1]  
encoding_dim = 32  

input_layer = Input(shape=(input_dim,))  
encoded = Dense(encoding_dim, activation='relu')(input_layer)  
decoded = Dense(input_dim, activation='sigmoid')(encoded)  

autoencoder = Model(input_layer, decoded)  
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')  

# Train  
autoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test), verbose=0)  

# Visualize  
decoded_imgs = autoencoder.predict(x_test[:10])  
plt.figure(figsize=(20,4))  
for i in range(10):  
    # Original  
    ax = plt.subplot(2,10,i+1)  
    plt.imshow(x_test[i].reshape(28,28))  
    plt.axis('off')  
    # Reconstructed  
    ax = plt.subplot(2,10,i+11)  
    plt.imshow(decoded_imgs[i].reshape(28,28))  
    plt.axis('off')  
plt.suptitle("Original and Reconstructed Images")  
plt.show()
```

### 2. Denoising Autoencoder
```
import numpy as np  
import matplotlib.pyplot as plt  
from tensorflow.keras.layers import Input, Dense  
from tensorflow.keras.models import Model  
from tensorflow.keras.datasets import mnist  

# Load data  
(x_train, _), (x_test, _) = mnist.load_data()  

# Normalize  
x_train = x_train.astype('float32') / 255.  
x_test = x_test.astype('float32') / 255.  

# Flatten  
x_train = x_train.reshape((len(x_train), -1))  
x_test = x_test.reshape((len(x_test), -1))  

# Add noise  
noise_factor = 0.5  
x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)  
x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)  
x_train_noisy = np.clip(x_train_noisy, 0., 1.)  
x_test_noisy = np.clip(x_test_noisy, 0., 1.)  

# Autoencoder architecture  
input_dim = x_train.shape[1]  
encoding_dim = 32  

input_layer = Input(shape=(input_dim,))  
encoded = Dense(encoding_dim, activation='relu')(input_layer)  
decoded = Dense(input_dim, activation='sigmoid')(encoded)  

autoencoder = Model(input_layer, decoded)  
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')  

# Train on noisy data to reconstruct original  
autoencoder.fit(x_train_noisy, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test_noisy, x_test), verbose=0)  

# Denoising reconstructed images  
decoded_imgs = autoencoder.predict(x_test_noisy[:10])  

# Plot  
plt.figure(figsize=(20,4))  
for i in range(10):  
    # Noisy input  
    ax = plt.subplot(3,10,i+1)  
    plt.imshow(x_test_noisy[i].reshape(28,28))  
    plt.axis('off')  
    # Original  
    ax = plt.subplot(3,10,i+11)  
    plt.imshow(x_test[i].reshape(28,28))  
    plt.axis('off')  
    # Reconstructed (denoised)  
    ax = plt.subplot(3,10,i+21)  
    plt.imshow(decoded_imgs[i].reshape(28,28))  
    plt.axis('off')  
plt.suptitle("Noisy Input, Original, and Denoised Output")  
plt.show()
```

### 3. Sparse Autoencoder

```
import numpy as np  
import matplotlib.pyplot as plt  
from tensorflow.keras.layers import Input, Dense  
from tensorflow.keras.models import Model  
from tensorflow.keras.datasets import mnist  

# Load and process data  
(x_train, _), (x_test, _) = mnist.load_data()  
x_train = x_train.astype('float32') / 255.  
x_test = x_test.astype('float32') / 255.  
x_train = x_train.reshape((len(x_train), -1))  
x_test = x_test.reshape((len(x_test), -1))  

# Autoencoder with sparsity constraint  
input_dim = x_train.shape[1]  
encoding_dim = 32  

input_layer = Input(shape=(input_dim,))  
encoded = Dense(encoding_dim, activation='relu', activity_regularizer='l1')(input_layer)  
decoded = Dense(input_dim, activation='sigmoid')(encoded)  

autoencoder = Model(input_layer, decoded)  
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')  

# Train  
autoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test), verbose=0)  

# Visualize  
decoded_imgs = autoencoder.predict(x_test[:10])  
plt.figure(figsize=(20,4))  
for i in range(10):  
    plt.subplot(2,10,i+1)  
    plt.imshow(x_test[i].reshape(28,28))  
    plt.axis('off')  
    plt.subplot(2,10,i+11)  
    plt.imshow(decoded_imgs[i].reshape(28,28))  
    plt.axis('off')  
plt.suptitle("Original and Sparse Autoencoder Output")  
plt.show()
```

### 4. Variational Autoencoder (VAE)

```
import numpy as np  
import tensorflow as tf  
from tensorflow.keras.layers import Input, Dense, Lambda  
from tensorflow.keras.models import Model  
from tensorflow.keras.datasets import mnist  

# Load data  
(x_train, _), (x_test, _) = mnist.load_data()  
x_train = x_train.astype('float32') / 255.  
x_test = x_test.astype('float32') / 255.  
x_train = x_train.reshape((len(x_train), -1))  
x_test = x_test.reshape((len(x_test), -1))  

original_dim = x_train.shape[1]  
intermediate_dim = 64  
latent_dim = 2  # Smaller for visualization  

# Encoder  
inputs = Input(shape=(original_dim,))  
h = Dense(intermediate_dim, activation='relu')(inputs)  
z_mean = Dense(latent_dim)(h)  
z_log_var = Dense(latent_dim)(h)  

def sampling(args):  
    z_mean, z_log_var = args  
    epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim))  
    return z_mean + tf.exp(0.5 * z_log_var) * epsilon  

z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])  

# Decoder  
decoder_h = Dense(intermediate_dim, activation='relu')  
decoder_mean = Dense(original_dim, activation='sigmoid')  

h_decoded = decoder_h(z)  
x_decoded_mean = decoder_mean(h_decoded)  

# VAE model  
vae = Model(inputs, x_decoded_mean)  

# Loss  
reconstruction_loss = tf.keras.losses.binary_crossentropy(inputs, x_decoded_mean)  
reconstruction_loss *= original_dim  
kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)  
vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)  
vae.add_loss(vae_loss)  

# Compile and train  
vae.compile(optimizer='adam')  
vae.fit(x_train, epochs=20, batch_size=128, validation_data=(x_test, None), verbose=0)  

# Visualize latent space  
import matplotlib.pyplot as plt  
encoder = Model(inputs, z_mean)  
z_vals = encoder.predict(x_test[:1000])  
plt.scatter(z_vals[:, 0], z_vals[:, 1], alpha=0.5)  
plt.xlabel("Z[0]")  
plt.ylabel("Z[1]")  
plt.title("Latent Space of Variational Autoencoder")  
plt.show()
```
## Output

1. Basic Autoencoder
****
![[Pasted image 20250507135918.png]]

2. Denoising Autoencoder
