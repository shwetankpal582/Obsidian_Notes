WAP TO DEMONSTRATE AUTO ENCODER

-  DENOISING AUTO ENCODER
-  SPARSE AUTO ENCODER
-  VARIATIONAL AUTO ENCODER

## Code

```
# 1. Setup
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Lambda
from tensorflow.keras.models import Model
from tensorflow.keras import regularizers
from tensorflow.keras.datasets import mnist
import tensorflow.keras.backend as K

(x_train, _), (x_test, _) = mnist.load_data()
x_train = x_train.astype("float32") / 255.
x_test = x_test.astype("float32") / 255.
x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))
x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))


# 2. Denoising Autoencoder
# Add noise
noise_factor = 0.5
x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) 
x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) 
x_train_noisy = np.clip(x_train_noisy, 0., 1.)
x_test_noisy = np.clip(x_test_noisy, 0., 1.)

input_img = Input(shape=(28, 28, 1))
x = Flatten()(input_img)
x = Dense(128, activation='relu')(x)
encoded = Dense(64, activation='relu')(x)
x = Dense(128, activation='relu')(encoded)
decoded = Dense(28*28, activation='sigmoid')(x)
decoded = Reshape((28, 28, 1))(decoded)

autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
autoencoder.fit(x_train_noisy, x_train, epochs=5, batch_size=256, shuffle=True, validation_data=(x_test_noisy, x_test))

decoded_imgs = autoencoder.predict(x_test_noisy)

# 3. Sparse Autoencoder

input_img = Input(shape=(28, 28, 1))
x = Flatten()(input_img)
x = Dense(128, activation='relu', activity_regularizer=regularizers.l1(1e-5))(x)
encoded = Dense(64, activation='relu')(x)
x = Dense(128, activation='relu')(encoded)
decoded = Dense(28*28, activation='sigmoid')(x)
decoded = Reshape((28, 28, 1))(decoded)

sparse_autoencoder = Model(input_img, decoded)
sparse_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
sparse_autoencoder.fit(x_train, x_train, epochs=5, batch_size=256, shuffle=True, validation_data=(x_test, x_test))

decoded_sparse = sparse_autoencoder.predict(x_test)

# 4. Variational Autoencoder (VAE)

latent_dim = 2

inputs = Input(shape=(28, 28, 1))
x = Flatten()(inputs)
h = Dense(256, activation='relu')(x)

z_mean = Dense(latent_dim)(h)
z_log_var = Dense(latent_dim)(h)

def sampling(args):
    z_mean, z_log_var = args
    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)
    return z_mean + K.exp(0.5 * z_log_var) * epsilon

z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])
encoder = Model(inputs, z)

decoder_input = Input(shape=(latent_dim,))
d = Dense(256, activation='relu')(decoder_input)
d = Dense(784, activation='sigmoid')(d)
outputs = Reshape((28, 28, 1))(d)
decoder = Model(decoder_input, outputs)

outputs = decoder(z)
vae = Model(inputs, outputs)

# 4. Custom loss
reconstruction_loss = tf.keras.losses.binary_crossentropy(K.flatten(inputs), K.flatten(outputs))
reconstruction_loss *= 784
kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)
kl_loss = K.sum(kl_loss, axis=-1)
kl_loss *= -0.5
vae_loss = K.mean(reconstruction_loss + kl_loss)
vae.add_loss(vae_loss)
vae.compile(optimizer='adam')
vae.fit(x_train, x_train, epochs=5, batch_size=256, validation_data=(x_test, x_test))

decoded_vae = vae.predict(x_test)

# 5. def show_images(original, noisy=None, decoded=None, title=""):
    n = 10
    plt.figure(figsize=(18, 6))
    for i in range(n):
        # Original
        ax = plt.subplot(3, n, i + 1)
        plt.imshow(original[i].reshape(28, 28), cmap="gray")
        plt.axis("off")
        if i == 0:
            ax.set_title("Original")
        
        # Noisy
        if noisy is not None:
            ax = plt.subplot(3, n, i + 1 + n)
            plt.imshow(noisy[i].reshape(28, 28), cmap="gray")
            plt.axis("off")
            if i == 0:
                ax.set_title("Noisy")
        
        # Decoded
        if decoded is not None:
            ax = plt.subplot(3, n, i + 1 + 2 * n)
            plt.imshow(decoded[i].reshape(28, 28), cmap="gray")
            plt.axis("off")
            if i == 0:
                ax.set_title("Decoded")
    plt.suptitle(title, fontsize=16)
    plt.show()

# Visualize each
show_images(x_test, x_test_noisy, decoded_imgs, "Denoising Autoencoder")
show_images(x_test, decoded=decoded_sparse, title="Sparse Autoencoder")
show_images(x_test, decoded=decoded_vae, title="Variational Autoencoder")

```

## Output

