PRACTICAL : 11

WAP TO DEMONSTRATE DIFFERENT LOSS FUNCTION IN KERAS
## Code

```
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

# --------------------------
# ðŸ“Œ 1. Regression Example
# --------------------------
print("\n=== Regression Losses ===")

# Sample regression data
X_reg = np.linspace(0, 1, 100).reshape(-1, 1)
y_reg = 2 * X_reg + 1

# Split data
Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_reg, y_reg, test_size=0.2)

# MSE Loss Model
model_mse = Sequential([Dense(10, activation='relu', input_shape=(1,)), Dense(1)])
model_mse.compile(optimizer='adam', loss='mean_squared_error')
model_mse.fit(Xr_train, yr_train, epochs=50, verbose=0)
loss_mse = model_mse.evaluate(Xr_test, yr_test, verbose=0)
print(f"MSE Loss: {loss_mse:.4f}")

# MAE Loss Model
model_mae = Sequential([Dense(10, activation='relu', input_shape=(1,)), Dense(1)])
model_mae.compile(optimizer='adam', loss='mean_absolute_error')
model_mae.fit(Xr_train, yr_train, epochs=50, verbose=0)
loss_mae = model_mae.evaluate(Xr_test, yr_test, verbose=0)
print(f"MAE Loss: {loss_mae:.4f}")

# --------------------------
# ðŸ“Œ 2. Binary Classification
# --------------------------
print("\n=== Binary Crossentropy ===")

# Sample binary data
X_bin = np.random.rand(100, 2)
y_bin = (X_bin[:, 0] + X_bin[:, 1] > 1).astype(int)  # Simple threshold

Xb_train, Xb_test, yb_train, yb_test = train_test_split(X_bin, y_bin, test_size=0.2)

model_bin = Sequential([Dense(10, activation='relu', input_shape=(2,)), Dense(1, activation='sigmoid')])
model_bin.compile(optimizer='adam', loss='binary_crossentropy')
model_bin.fit(Xb_train, yb_train, epochs=50, verbose=0)
loss_bin = model_bin.evaluate(Xb_test, yb_test, verbose=0)
print(f"Binary Crossentropy Loss: {loss_bin:.4f}")

# --------------------------
# ðŸ“Œ 3. Multi-class Classification
# --------------------------
print("\n=== Categorical Crossentropy ===")

# Sample multi-class data
X_cat = np.random.rand(200, 4)
y_cat = np.random.randint(0, 3, 200)  # Classes: 0, 1, 2
y_cat_onehot = to_categorical(y_cat, num_classes=3)

Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_cat, y_cat_onehot, test_size=0.2)

model_cat = Sequential([
    Dense(10, activation='relu', input_shape=(4,)),
    Dense(3, activation='softmax')
])
model_cat.compile(optimizer='adam', loss='categorical_crossentropy')
model_cat.fit(Xc_train,

```

## Input

```
=== Regression Losses ===
MSE Loss: 0.0007
MAE Loss: 0.0213

=== Binary Crossentropy ===
Binary Crossentropy Loss: 0.5994

=== Categorical Crossentropy ===
Categorical Crossentropy Loss: 1.0689

```

## Output

```

```